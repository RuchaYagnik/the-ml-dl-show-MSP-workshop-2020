{
  "cells": [
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "# The Machine Learning & Deep Learning Show"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### By Vedant Bahel & Harsh Aryan"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#importing lib\nimport numpy as np\nimport pandas as pd",
      "execution_count": 313,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#importing data\ndataset= pd.read_csv(\"IRIS.csv\")",
      "execution_count": 314,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(dataset.head(5))",
      "execution_count": 315,
      "outputs": [
        {
          "output_type": "stream",
          "text": "   sepal_length  sepal_width  petal_length  petal_width      species\n0           5.1          3.5           1.4          0.2  Iris-setosa\n1           4.9          3.0           1.4          0.2  Iris-setosa\n2           4.7          3.2           1.3          0.2  Iris-setosa\n3           4.6          3.1           1.5          0.2  Iris-setosa\n4           5.0          3.6           1.4          0.2  Iris-setosa\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "dataset[\"species\"] = dataset[\"species\"].astype('category')\ndataset[\"Encoded_Species\"] = dataset[\"species\"].cat.codes",
      "execution_count": 316,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(dataset.head(5))",
      "execution_count": 317,
      "outputs": [
        {
          "output_type": "stream",
          "text": "   sepal_length  sepal_width  petal_length  petal_width      species  \\\n0           5.1          3.5           1.4          0.2  Iris-setosa   \n1           4.9          3.0           1.4          0.2  Iris-setosa   \n2           4.7          3.2           1.3          0.2  Iris-setosa   \n3           4.6          3.1           1.5          0.2  Iris-setosa   \n4           5.0          3.6           1.4          0.2  Iris-setosa   \n\n   Encoded_Species  \n0                0  \n1                0  \n2                0  \n3                0  \n4                0  \n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#define X & Y\nX= dataset.iloc[:,0:4].values",
      "execution_count": 318,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "Y= dataset.iloc[:,5].values",
      "execution_count": 319,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#split \nfrom sklearn.model_selection import train_test_split\nX_train, X_test,Y_train, Y_test= train_test_split(X,Y, test_size=0.1)\n\naccuracy_results = {}\n\ndef cal_result(Y_test, Y_pred):\n    from sklearn.metrics import accuracy_score\n    accuracy = accuracy_score(Y_test, Y_pred)\n    return {'accuracy': accuracy}  ",
      "execution_count": 320,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Logistics Regression"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.linear_model import LogisticRegression\nlogclass= LogisticRegression()\nlogclass.fit(X_train, Y_train)",
      "execution_count": 321,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/home/nbuser/anaconda3_501/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\n/home/nbuser/anaconda3_501/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n  \"this warning.\", FutureWarning)\n",
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "execution_count": 321,
          "data": {
            "text/plain": "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='warn',\n          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n          tol=0.0001, verbose=0, warm_start=False)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "Y_pred_log = logclass.predict(X_test)",
      "execution_count": 322,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n\naccuracy_results['Logistic Regression'] = cal_result(Y_test, Y_pred_log)\n\nprint(confusion_matrix(Y_test, Y_pred_log))\nprint(classification_report(Y_test, Y_pred_log))\nprint(accuracy_score(Y_test, Y_pred_log))",
      "execution_count": 323,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[[4 0 0]\n [0 6 0]\n [0 0 5]]\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00         4\n           1       1.00      1.00      1.00         6\n           2       1.00      1.00      1.00         5\n\n   micro avg       1.00      1.00      1.00        15\n   macro avg       1.00      1.00      1.00        15\nweighted avg       1.00      1.00      1.00        15\n\n1.0\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## KNN Classifier"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.neighbors import KNeighborsClassifier\nknn= KNeighborsClassifier()\nknn.fit(X_train, Y_train)\nY_pred_knn = knn.predict(X_test)",
      "execution_count": 324,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n\naccuracy_results['KNN Classifier'] = cal_result(Y_test, Y_pred_knn)\n\n\nprint(confusion_matrix(Y_test, Y_pred_knn))\nprint(classification_report(Y_test, Y_pred_knn))\nprint(accuracy_score(Y_test, Y_pred_knn))",
      "execution_count": 325,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[[4 0 0]\n [0 6 0]\n [0 0 5]]\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00         4\n           1       1.00      1.00      1.00         6\n           2       1.00      1.00      1.00         5\n\n   micro avg       1.00      1.00      1.00        15\n   macro avg       1.00      1.00      1.00        15\nweighted avg       1.00      1.00      1.00        15\n\n1.0\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Decision Tree"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.tree import DecisionTreeClassifier\n\n## Complete the code\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n\nclassifier = DecisionTreeClassifier()\nclassifier.fit(X_train, Y_train)\n\nY_pred_decision= classifier.predict(X_test)\n\naccuracy_results['Decision Tree'] = cal_result(Y_test, Y_pred_decision)\n\n\nprint(confusion_matrix(Y_test, Y_pred_decision))\nprint(classification_report(Y_test, Y_pred_decision))\nprint(accuracy_score(Y_test, Y_pred_decision))",
      "execution_count": 326,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[[4 0 0]\n [0 6 0]\n [0 0 5]]\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00         4\n           1       1.00      1.00      1.00         6\n           2       1.00      1.00      1.00         5\n\n   micro avg       1.00      1.00      1.00        15\n   macro avg       1.00      1.00      1.00        15\nweighted avg       1.00      1.00      1.00        15\n\n1.0\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Random Forest"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.ensemble import RandomForestClassifier\n\n## Complete the code\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\n\nregressor = RandomForestClassifier(n_estimators=10, random_state=0)\nregressor.fit(X_train, Y_train)\nY_pred_random = regressor.predict(X_test)\n\naccuracy_results['Random Forest'] = cal_result(Y_test, Y_pred_random)\n\n\nprint(confusion_matrix(Y_test,Y_pred_random))\nprint(classification_report(Y_test,Y_pred_random))\nprint(accuracy_score(Y_test, Y_pred_random))",
      "execution_count": 327,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[[4 0 0]\n [0 6 0]\n [0 0 5]]\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00         4\n           1       1.00      1.00      1.00         6\n           2       1.00      1.00      1.00         5\n\n   micro avg       1.00      1.00      1.00        15\n   macro avg       1.00      1.00      1.00        15\nweighted avg       1.00      1.00      1.00        15\n\n1.0\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Which model performs best accuracy wise?"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "result = accuracy_results.values()\ndef get_accuracy(res):\n    return res['accuracy']\nmax_accuracy = (max(result, key=get_accuracy))['accuracy']\nprint('Max Accuracy: ' + str(max_accuracy))\n\nprint('\\nBest Models:')\nfor (method, res) in accuracy_results.items():\n    if(res['accuracy'] == max_accuracy):\n        print(method)",
      "execution_count": 328,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Max Accuracy: 1.0\n\nBest Models:\nLogistic Regression\nKNN Classifier\nDecision Tree\nRandom Forest\n",
          "name": "stdout"
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}